# Sprint 27B: Scheduler + JSONL State - COMPLETE

**Date**: 2025-10-03 10:58
**Status**: ✅ All tests passing (21 new tests, 120 total passing)

## Summary

Implemented lightweight cron-like scheduler with JSONL state tracking. Single-process scheduler loads YAML configs, matches cron expressions, de-duplicates enqueued runs, and launches DAG executions respecting max_parallel limit. All scheduler events recorded to append-only state store.

---

## Files Added (3)

1. **src/orchestrator/state_store.py** - JSONL append-only state storage (148 lines)
2. **src/orchestrator/scheduler.py** - Cron-like scheduler with threading (327 lines)
3. **configs/schedules/weekly_ops.every5m.yaml** - Example schedule config
4. **tests/test_state_store.py** - State store tests (12 tests)
5. **tests/test_scheduler_core.py** - Scheduler tests (9 tests)

## Files Updated (1)

1. **docs/ORCHESTRATION.md** - Added "Scheduling & State" section (+60 lines)

---

## Features Delivered

### 1. JSONL State Store

**File:** `src/orchestrator/state_store.py` (148 lines)

Append-only JSONL storage for scheduler events and DAG run metadata.

**Core Functions:**
```python
record_event(event: dict, path: str | None) -> None
last_runs(limit: int = 20, path: str | None) -> list[dict]
index_by(field: str, limit: int = 100, path: str | None) -> dict[str, list[dict]]
```

**Features:**
- Auto-creates parent directories
- Adds timestamp if not present (uses `datetime.now(UTC)`)
- Skips corrupted JSON lines gracefully
- Thread-safe append operations
- Simple indexing for querying by field

**Default Path:** `logs/orchestrator_state.jsonl` (via `STATE_STORE_PATH` env var)

### 2. Scheduler

**File:** `src/orchestrator/scheduler.py` (327 lines)

Cron-like scheduler for automated DAG execution.

**Core Functions:**
```python
parse_cron(expr: str) -> callable  # Parses */n minute and * wildcard
load_schedules(schedules_dir: str) -> list[dict]
tick_once(now, schedules, run_queue) -> None
drain_queue(run_queue, max_parallel=3) -> list[dict]
```

**Supported Cron Syntax:**
- `*/5 * * * *` - Every 5 minutes
- `0 9 * * *` - Daily at 9:00 AM
- `0 */2 * * *` - Every 2 hours
- `* * * * *` - Every minute (not recommended)

**De-duplication:**
Uses `{schedule_id, minute}` key to prevent double-enqueue within same minute.

**CLI Modes:**
```bash
# Single tick (CI-safe)
python -m src.orchestrator.scheduler --dir configs/schedules --once

# Continuous serving
python -m src.orchestrator.scheduler --dir configs/schedules --serve
```

**Concurrency:**
ThreadPoolExecutor launches up to `SCHED_MAX_PARALLEL` concurrent DAG runs (default 3).

**State Events Recorded:**
- `schedule_enqueued` - Schedule matched, run queued
- `run_started` - DAG execution started
- `run_finished` - DAG execution completed (success/failed)

### 3. Schedule Config

**File:** `configs/schedules/weekly_ops.every5m.yaml`

Example schedule configuration:
```yaml
- id: weekly_ops_chain
  cron: "*/5 * * * *"
  dag: configs/dags/weekly_ops_chain.min.yaml
  tenant: local-dev
  enabled: true
```

Multiple schedules can be defined in a single YAML file or split across multiple files in the directory.

### 4. Documentation Update

**File:** `docs/ORCHESTRATION.md` (+60 lines)

Added "Scheduling & State" section with:
- State store API reference
- Scheduler usage (--once vs --serve)
- Cron expression format
- Environment variables
- Event types and de-duplication logic
- Log reading examples

---

## Tests (21 new, 120 passing)

### State Store Tests (12 tests)

```python
test_record_and_read_events
test_last_runs_respects_limit
test_empty_file_returns_empty_list
test_missing_file_returns_empty_list
test_corrupted_lines_skipped
test_auto_adds_timestamp
test_index_by_groups_events
test_index_by_respects_limit
test_index_by_empty_file
test_concurrent_writes_append_correctly
```

### Scheduler Tests (9 tests)

```python
test_parse_cron_every_5_minutes
test_parse_cron_wildcard
test_parse_cron_specific_hour
test_tick_once_enqueues_matching_schedule
test_tick_once_skips_non_matching
test_tick_once_skips_disabled
test_tick_once_deduplicates_same_minute
test_drain_queue_executes_runs
test_drain_queue_respects_max_parallel
test_drain_queue_handles_failures
test_drain_queue_clears_queue
```

**Test Results:**
```
tests/test_state_store.py ............ (12 passed)
tests/test_scheduler_core.py ......... (9 passed)

Sprint 27B: 21 tests passing
Sprint 27A: 11 tests passing
Sprint 26: 71 tests passing
──────────────────────────
Total: 120 tests passing (including previous sprints)
```

---

## Environment Variables

```bash
# State store
STATE_STORE_PATH=logs/orchestrator_state.jsonl

# Orchestrator events (from Sprint 27A)
ORCH_EVENTS_PATH=logs/orchestrator_events.jsonl

# Scheduler config
SCHED_TICK_MS=1000           # Tick interval in milliseconds
SCHED_MAX_PARALLEL=3         # Max concurrent DAG runs
```

---

## Usage Examples

### 1. Define a Schedule

Create `configs/schedules/daily_reports.yaml`:
```yaml
- id: daily_morning_report
  cron: "0 9 * * *"  # Daily at 9:00 AM
  dag: configs/dags/morning_report.yaml
  tenant: acme-corp
  enabled: true
```

### 2. Run Once (CI/Testing)

```bash
python -m src.orchestrator.scheduler --dir configs/schedules --once
```

Output:
```
Loaded 1 schedule(s) from configs/schedules
Running single tick...
Enqueued 0 run(s)
```

### 3. Run Continuously

```bash
python -m src.orchestrator.scheduler --dir configs/schedules --serve
```

Output:
```
Loaded 1 schedule(s) from configs/schedules
Serving scheduler (tick=1000ms, max_parallel=3)...
Press Ctrl+C to stop
[14:05:00] Draining 1 run(s)...
```

### 4. Query State Store

```python
from src.orchestrator.state_store import last_runs, index_by

# Get last 20 events
events = last_runs(limit=20)
for event in events:
    print(f"{event['timestamp']} - {event['event']}")

# Index by schedule_id
by_schedule = index_by("schedule_id", limit=100)
for schedule_id, runs in by_schedule.items():
    print(f"{schedule_id}: {len(runs)} runs")
```

---

## Integration with Sprint 27A

- Scheduler invokes `run_dag()` from `src/orchestrator/runner.py`
- DAG events continue to write to `ORCH_EVENTS_PATH`
- State store tracks higher-level scheduler events
- Both logs complement each other (scheduler-level + task-level)

---

## What We Learned

1. **Append-only JSONL is perfect for event logs** - Simple, fast, easy to query with standard tools (grep, jq, Python). No database overhead.

2. **De-duplication by minute prevents cron double-execution** - Using `{schedule_id, minute}` key ensures same schedule doesn't enqueue twice if tick runs multiple times in same minute.

3. **ThreadPoolExecutor simplifies concurrent execution** - No need for complex async code; thread pool with max_workers handles concurrency limit naturally.

---

## Known Limitations

1. **Single-process only** - No distributed scheduler coordination (acceptable for current scale)
2. **Minimal cron syntax** - Supports */n and * only (sufficient for MVP)
3. **No persistence of run queue** - Queue clears on restart (state store tracks completed runs only)
4. **No schedule conflict detection** - Multiple schedules can enqueue at same time (respects max_parallel during drain)

---

## Next Sprint Commitment

**Sprint 27C** (or Sprint 28): Dashboard observability for scheduler + DAG runs with real-time metrics, run history, and schedule status visualization.

---

## Rollback Procedure

If Sprint 27B causes issues:

```bash
# Checkout Sprint 27A
git checkout sprint/27A-dag-core

# Scheduler stops, DAG execution via CLI still works
# State events no longer written but existing logs preserved
```

---

**Sprint 27B Complete** ✅
**Ready for Sprint 27C or Sprint 28**
